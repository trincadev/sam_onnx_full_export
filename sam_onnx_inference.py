# -*- coding: utf-8 -*-
"""Copy of sam_onnx_inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rdHYDPNk2UspQsfS7XhBsqGVBnkCJfNE
"""

# Segment Anything Image Segmentation examples using ONNX
#
# Before running this code, ensure that you used the export_onnx.ipynb notebook
# to export both SAM image encoder and SAM masks decoder to vit_b_encoder.onnx
# and vit_b_decoder.onnx.
#
# if matplotlib doesn't show images try exec this script with pycharm
import logging

logging.basicConfig(level=logging.INFO)


if __name__ == '__main__':
    from matplotlib import pyplot as plt
    import onnxruntime as ort
    from PIL import Image
    from urllib import request

    from helpers import preprocess_image, padding_tensor, get_mask

    logging.info("start...")
    output_image = "teglio_1280x960.jpg"
    request.urlretrieve(
        'https://gitlab.com/aletrn/samgis_core/-/raw/main/tests/events/samexporter_predict/teglio/teglio_1280x960.jpg',
        output_image
    )

    img0 = Image.open(output_image)
    img = img0.convert("RGB")
    img_input_size = {"original_size": img.size}

    img, img_original_size = preprocess_image(img)
    img_input_size["resized_size"] = img.size
    logging.info(f"img.size (PIL, same as numpy array shape): {img.size} .")

    input_tensor = padding_tensor(img)

    # 2. GET IMAGE EMBEDDINGS USING IMAGE ENCODER
    encoder = ort.InferenceSession("mobile_sam.encoder.onnx")
    outputs = encoder.run(None, {"images": input_tensor})
    embeddings = outputs[0]

    logging.info(f"embedding shape: {embeddings.shape}")

    # 3. DECODE MASKS FROM IMAGE EMBEDDINGS

    # 3.1 OPTION 1: Use single point as a prompt
    prompt = [{
            "type": "rectangle",
            "data": [132, 157, 256, 325]
        }, {
            "type": "point",
            "data": [321, 230],
            "label": 0
        }]
    masks, res2, res3 = get_mask(prompt, img_input_size, embeddings)

    logging.info(f"found {len(masks)} masks...")

    # POSTPROCESS MASK
    mask = masks[0][0]
    mask = (mask > 0).astype('uint8') * 255

    logging.info(f"mask shape: {mask.shape}.")

    fig, ax = plt.subplot_mosaic([
        ['img', 'mask']
    ], figsize=(15, 10))

    # VISUALIZE MASK
    img_mask = Image.fromarray(masks[0][0] > 0)
    logging.info(img_mask.size, img.size, img_original_size)
    ax["img"].imshow(img)
    ax["mask"].imshow(img_mask)
    plt.show()

    logging.info("end!")
